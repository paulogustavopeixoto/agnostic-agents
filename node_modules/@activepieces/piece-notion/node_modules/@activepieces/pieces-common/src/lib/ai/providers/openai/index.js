"use strict";
Object.defineProperty(exports, "__esModule", { value: true });
exports.openaiModels = exports.openai = void 0;
const tslib_1 = require("tslib");
const __1 = require("../..");
const shared_1 = require("@activepieces/shared");
const openai_1 = tslib_1.__importDefault(require("openai"));
const utils_1 = require("../utils");
const pieces_framework_1 = require("@activepieces/pieces-framework");
const openai = ({ proxyUrl, engineToken }) => {
    const openaiApiVersion = 'v1';
    const sdk = new openai_1.default({
        apiKey: engineToken,
        baseURL: `${proxyUrl}/${openaiApiVersion}`,
    });
    return {
        provider: 'OPENAI',
        function: {
            call: (params) => tslib_1.__awaiter(void 0, void 0, void 0, function* () {
                var _a;
                const messages = params.messages.map((message) => ({
                    role: 'user',
                    content: [
                        { type: 'text', text: message.content },
                    ],
                }));
                if (params.image) {
                    messages.push({
                        role: 'user',
                        content: [
                            { type: 'image_url', image_url: { url: `data:image/${params.image.extension};base64,${params.image.base64}` } },
                        ],
                    });
                }
                const completion = yield sdk.chat.completions.create({
                    model: params.model,
                    messages: messages,
                    max_tokens: params.maxTokens,
                    tools: params.functions.map((functionDefinition) => ({
                        type: 'function',
                        function: {
                            name: functionDefinition.name,
                            description: functionDefinition.description,
                            parameters: functionDefinition.arguments,
                        },
                    })),
                });
                const toolCall = (_a = completion.choices[0].message.tool_calls) === null || _a === void 0 ? void 0 : _a[0];
                return {
                    choices: completion.choices.map((choice) => {
                        var _a;
                        return ({
                            role: __1.AIChatRole.ASSISTANT,
                            content: (_a = choice.message.content) !== null && _a !== void 0 ? _a : '',
                        });
                    }),
                    call: toolCall
                        ? {
                            id: toolCall.id,
                            function: {
                                name: toolCall.function.name,
                                arguments: JSON.parse(toolCall.function.arguments),
                            },
                        }
                        : null,
                    created: completion.created,
                    model: completion.model,
                    usage: completion.usage && {
                        completionTokens: completion.usage.completion_tokens,
                        promptTokens: completion.usage.prompt_tokens,
                        totalTokens: completion.usage.total_tokens,
                    },
                };
            }),
        },
        image: {
            generate: (params) => tslib_1.__awaiter(void 0, void 0, void 0, function* () {
                const mapper = findImageMapper(params.model);
                const input = yield mapper.encodeInput(params);
                const response = yield sdk.images.generate(input);
                return mapper.decodeOutput(response);
            }),
        },
        chat: {
            text: (params) => tslib_1.__awaiter(void 0, void 0, void 0, function* () {
                var _a;
                const completion = yield sdk.chat.completions.create({
                    model: params.model,
                    messages: params.messages.map((message) => ({
                        role: message.role === 'user' ? 'user' : 'assistant',
                        content: message.content,
                    })),
                    temperature: Math.tanh((_a = params.creativity) !== null && _a !== void 0 ? _a : 100),
                    max_tokens: params.maxTokens,
                    stop: params.stop,
                });
                return {
                    choices: completion.choices.map((choice) => {
                        var _a;
                        return ({
                            role: __1.AIChatRole.ASSISTANT,
                            content: (_a = choice.message.content) !== null && _a !== void 0 ? _a : '',
                        });
                    }),
                    created: completion.created,
                    model: completion.model,
                    usage: completion.usage && {
                        completionTokens: completion.usage.completion_tokens,
                        promptTokens: completion.usage.prompt_tokens,
                        totalTokens: completion.usage.total_tokens,
                    },
                };
            })
        },
        moderation: {
            create: (params) => tslib_1.__awaiter(void 0, void 0, void 0, function* () {
                var _a;
                const inputs = [];
                if (params.text) {
                    inputs.push({ type: 'text', text: params.text });
                }
                for (const image of (_a = params.images) !== null && _a !== void 0 ? _a : []) {
                    inputs.push({
                        type: 'image_url',
                        image_url: {
                            url: `data:image/${image.extension};base64,${image.base64}`,
                        },
                    });
                }
                const response = yield sdk.moderations.create({
                    input: inputs,
                    model: params.model,
                });
                return response.results[0];
            }),
        },
    };
};
exports.openai = openai;
const findImageMapper = (model) => {
    var _a;
    const mapper = (_a = exports.openaiModels.find((m) => m.value === model)) === null || _a === void 0 ? void 0 : _a.mapper;
    if ((0, shared_1.isNil)(mapper) ||
        !('__tag' in mapper) ||
        mapper.__tag !== utils_1.ModelType.IMAGE) {
        throw new Error(`OpenAI image model ${model} not found`);
    }
    return mapper;
};
const openaiImageMapper = (0, utils_1.imageMapper)({
    encodeInput: (params) => tslib_1.__awaiter(void 0, void 0, void 0, function* () {
        var _a;
        return {
            model: params.model,
            prompt: params.prompt,
            quality: (_a = params.advancedOptions) === null || _a === void 0 ? void 0 : _a['quality'],
            size: params.size,
            response_format: 'b64_json',
        };
    }),
    decodeOutput: (result) => tslib_1.__awaiter(void 0, void 0, void 0, function* () {
        const response = result;
        const imageBase64 = response.data[0].b64_json;
        return imageBase64 ? { image: imageBase64 } : null;
    }),
    advancedOptions: {
        quality: pieces_framework_1.Property.StaticDropdown({
            options: {
                options: [
                    { label: 'Standard', value: 'standard' },
                    { label: 'HD', value: 'hd' },
                ],
                disabled: false,
                placeholder: 'Select Image Quality',
            },
            defaultValue: 'standard',
            description: 'Standard images are less detailed and faster to generate, while HD images are more detailed but slower to generate.',
            displayName: 'Image Quality',
            required: true,
        }),
    },
});
exports.openaiModels = [
    (0, utils_1.model)({ label: 'gpt-4o', value: 'gpt-4o', supported: ['text', 'function'] }),
    (0, utils_1.model)({
        label: 'gpt-4o-mini',
        value: 'gpt-4o-mini',
        supported: ['text', 'function'],
    }),
    (0, utils_1.model)({
        label: 'gpt-4-turbo',
        value: 'gpt-4-turbo',
        supported: ['text', 'function'],
    }),
    (0, utils_1.model)({
        label: 'gpt-3.5-turbo',
        value: 'gpt-3.5-turbo',
        supported: ['text'],
    }),
    (0, utils_1.model)({ label: 'dall-e-3', value: 'dall-e-3', supported: ['image'] }).mapper(openaiImageMapper),
    (0, utils_1.model)({ label: 'dall-e-2', value: 'dall-e-2', supported: ['image'] }).mapper(openaiImageMapper),
    (0, utils_1.model)({
        label: 'omni-moderation-latest',
        value: 'omni-moderation-latest',
        supported: ['moderation'],
    }),
];
//# sourceMappingURL=index.js.map